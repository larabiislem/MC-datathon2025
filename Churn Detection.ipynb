{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875c0222",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load data (unchanged per request)\n",
    "try:\n",
    "    train_df = pd.read_csv('churn-detection/train.csv')\n",
    "    test_df = pd.read_csv('churn-detection/test.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: train.csv or test.csv not found. Please upload files to /content/ or specify correct path.\")\n",
    "    raise\n",
    "\n",
    "# Define columns\n",
    "categorical_columns = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',\n",
    "                      'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "                      'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',\n",
    "                      'PaperlessBilling', 'PaymentMethod']\n",
    "numerical_columns = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "service_cols = ['PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity',\n",
    "               'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
    "\n",
    "# Convert numerical columns, handle missing values\n",
    "for col in numerical_columns:\n",
    "    train_df[col] = pd.to_numeric(train_df[col], errors='coerce').fillna(0)\n",
    "    test_df[col] = pd.to_numeric(test_df[col], errors='coerce').fillna(0)\n",
    "\n",
    "# Encode target first\n",
    "train_df['Churn'] = train_df['Churn'].map({'No': 0, 'Yes': 1})\n",
    "\n",
    "# Encode categorical variables\n",
    "Encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    train_df[col] = le.fit_transform(train_df[col].astype(str))\n",
    "    test_df[col] = test_df[col].astype(str).apply(lambda x: x if x in le.classes_ else le.classes_[0])\n",
    "    le.classes_ = np.append(le.classes_, [x for x in test_df[col].unique() if x not in le.classes_])\n",
    "    test_df[col] = le.transform(test_df[col]).astype(int)\n",
    "    train_df[col] = train_df[col].astype(int)\n",
    "    Encoders[col] = le\n",
    "joblib.dump(Encoders, 'encoders_churn.pkl')\n",
    "\n",
    "# Target encoding for high-cardinality columns\n",
    "def target_encode(col, train_df, test_df, target='Churn'):\n",
    "    means = train_df.groupby(col)[target].mean()\n",
    "    train_df[f'{col}_target_enc'] = train_df[col].map(means)\n",
    "    test_df[f'{col}_target_enc'] = test_df[col].map(means).fillna(means.mean())\n",
    "    return train_df, test_df\n",
    "\n",
    "for col in ['PaymentMethod', 'Contract']:\n",
    "    train_df, test_df = target_encode(col, train_df, test_df)\n",
    "\n",
    "# Optimized feature engineering\n",
    "def add_features(df):\n",
    "    df['TotalServices'] = df[service_cols].eq('Yes').sum(axis=1)\n",
    "    df['MonthlyCharges_per_Tenure'] = df['MonthlyCharges'] / (df['tenure'] + 1e-6)\n",
    "    df['Log_MonthlyCharges'] = np.log1p(df['MonthlyCharges'])\n",
    "    df['TotalCharges_per_Tenure'] = df['TotalCharges'] / (df['tenure'] + 1e-6)\n",
    "    df['IsSeniorAndAlone'] = ((df['SeniorCitizen'] == 1) & (df['Dependents'] == 'No')).astype(int)\n",
    "    df['Loyalty_Score'] = df['tenure'] * (1 + df['Contract']).astype(int) + df['TotalServices']\n",
    "    df['Contract_tenure'] = df['tenure'] * df['Contract'].astype(int)\n",
    "    df['InternetService_MonthlyCharges'] = df['InternetService'].astype(int) * df['MonthlyCharges']\n",
    "    df['Tenure_to_Contract'] = df['tenure'] / (df['Contract'].map({0: 1, 1: 12, 2: 24}).fillna(1) + 1e-6)\n",
    "    df['MonthlyCharges_bin'] = pd.qcut(df['MonthlyCharges'], 5, labels=False, duplicates='drop')\n",
    "    return df\n",
    "\n",
    "train_df = add_features(train_df)\n",
    "test_df = add_features(test_df)\n",
    "\n",
    "# Clustering feature with n_init=10 to suppress warning\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "cluster_features = ['tenure', 'MonthlyCharges', 'TotalServices']\n",
    "train_df['Customer_Cluster'] = kmeans.fit_predict(train_df[cluster_features])\n",
    "test_df['Customer_Cluster'] = kmeans.predict(test_df[cluster_features])\n",
    "joblib.dump(kmeans, 'kmeans.pkl')\n",
    "\n",
    "# Polynomial features (limited to key interactions)\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\n",
    "numerical_cols_poly = ['tenure', 'MonthlyCharges']\n",
    "poly_features_train = poly.fit_transform(train_df[numerical_cols_poly])\n",
    "poly_features_test = poly.transform(test_df[numerical_cols_poly])\n",
    "poly_feature_names = poly.get_feature_names_out(numerical_cols_poly)\n",
    "train_df[poly_feature_names] = poly_features_train\n",
    "test_df[poly_feature_names] = poly_features_test\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_columns_extended = numerical_columns + ['MonthlyCharges_per_Tenure', 'Log_MonthlyCharges',\n",
    "                                                 'TotalCharges_per_Tenure', 'Loyalty_Score',\n",
    "                                                 'Contract_tenure', 'InternetService_MonthlyCharges',\n",
    "                                                 'Tenure_to_Contract', 'MonthlyCharges_bin',\n",
    "                                                 'Customer_Cluster', 'PaymentMethod_target_enc',\n",
    "                                                 'Contract_target_enc'] + list(poly_feature_names)\n",
    "scaler = StandardScaler()\n",
    "train_df[numerical_columns_extended] = scaler.fit_transform(train_df[numerical_columns_extended])\n",
    "test_df[numerical_columns_extended] = scaler.transform(test_df[numerical_columns_extended])\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "# Prepare features\n",
    "X = train_df.drop(['id', 'Churn'], axis=1)\n",
    "y = train_df['Churn']\n",
    "X_test_final = test_df[X.columns]\n",
    "\n",
    "# Pre-tuned base models (all on CPU)\n",
    "base_models = [\n",
    "    ('catboost', CatBoostClassifier(iterations=800, learning_rate=0.03, depth=8, l2_leaf_reg=3,\n",
    "                                    eval_metric='F1', verbose=0, random_state=42, class_weights=[1, 3])),\n",
    "    ('lightgbm', LGBMClassifier(n_estimators=700, learning_rate=0.05, max_depth=7, num_leaves=50,\n",
    "                                class_weight='balanced', random_state=42)),\n",
    "    ('xgboost', XGBClassifier(n_estimators=500, learning_rate=0.05, max_depth=6, subsample=0.8,\n",
    "                              scale_pos_weight=3, random_state=42)),  # CPU\n",
    "    ('rf', RandomForestClassifier(n_estimators=200, max_depth=20, min_samples_split=5,\n",
    "                                  class_weight='balanced', random_state=42, n_jobs=-1))\n",
    "]\n",
    "\n",
    "# Stacking classifier\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression(),\n",
    "                                    cv=5, n_jobs=-1)\n",
    "\n",
    "# Cross-validation and threshold optimization\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "best_f1, best_thresh = 0, 0.5\n",
    "val_preds = np.zeros(len(X))\n",
    "for train_idx, val_idx in skf.split(X, y):\n",
    "    X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    stacking_model.fit(X_tr, y_tr)\n",
    "    proba = stacking_model.predict_proba(X_val)[:, 1]\n",
    "    for thresh in np.arange(0.2, 0.81, 0.01):\n",
    "        score = f1_score(y_val, proba >= thresh)\n",
    "        if score > best_f1:\n",
    "            best_f1 = score\n",
    "            best_thresh = thresh\n",
    "    val_preds[val_idx] = proba\n",
    "\n",
    "print(f\"Best F1 (CV): {best_f1:.4f} at threshold {best_thresh:.2f}\")\n",
    "\n",
    "# Train final model\n",
    "stacking_model.fit(X, y)\n",
    "joblib.dump(stacking_model, 'stacking_model.pkl')\n",
    "\n",
    "# Predict on test set with blending\n",
    "test_probas = np.zeros((len(X_test_final), len(base_models)))\n",
    "for i, (name, model) in enumerate(base_models):\n",
    "    model.fit(X, y)\n",
    "    test_probas[:, i] = model.predict_proba(X_test_final)[:, 1]\n",
    "weights = [0.4, 0.3, 0.2, 0.1]  # CatBoost, LightGBM, XGBoost, RF\n",
    "blended_probas = np.average(test_probas, axis=1, weights=weights)\n",
    "test_proba = stacking_model.predict_proba(X_test_final)[:, 1]\n",
    "final_proba = 0.7 * test_proba + 0.3 * blended_probas\n",
    "test_pred = np.where(final_proba >= best_thresh, 'Yes', 'No')\n",
    "\n",
    "# Generate submission file\n",
    "submission = pd.DataFrame({'id': test_df['id'], 'Churn': test_pred})\n",
    "submission.to_csv('THEsubmission.csv', index=False)\n",
    "print(f\"Submission file generated: {submission.shape}\")\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(f\"Best F1 (CV): {best_f1:.4f} at threshold {best_thresh:.2f}\")\n",
    "print(\"=\"*100)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
